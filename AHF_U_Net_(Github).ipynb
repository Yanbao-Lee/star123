{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yanbao-Lee/star123/blob/main/AHF_U_Net_(Github).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WUfDyTBNKwRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ce93ef-2263-438e-ed7d-2cc433eb8d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I4DFfcYDK0rP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#import torchvision.transforms as transforms\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import CenterCrop\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "import cv2\n",
        "from torch.nn import Parameter\n",
        "# torch.manual_seed(42)\n",
        "# np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-xhMX1pnK0ti"
      },
      "outputs": [],
      "source": [
        "INPUT_IMAGE_HEIGHT = 240 #352 in original paper\n",
        "INPUT_IMAGE_WIDTH = 240\n",
        "BATCH_SIZE = 8\n",
        "# IMAGE_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/UNet++/Image/'\n",
        "# MASK_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/UNet++/Mask/'\n",
        "IMAGE_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/ISIC 2017/ISIC_2017/'\n",
        "MASK_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/ISIC 2017/ISIC-2017_Training_Part1_GroundTruth/'\n",
        "# IMAGE_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/ISIC/ISIC_Training_Data/'\n",
        "# MASK_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/ISIC/ISIC_Training_GroundTruth/'\n",
        "# IMAGE_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/ISIC18/ISIC2018Training_Input/Matched_ISIC_Training_Data/'\n",
        "# MASK_DATASET_PATH = '/content/gdrive/MyDrive/Phd work/ISIC18/ISIC2018Training_Input/Matched_ISIC_Training_GroundTruth/'\n",
        "\n",
        "seed = np.random.randint(2147483647)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "TEST_SPLIT = 0.30\n",
        "# determine the device to be used for training and evaluation\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lFLo4gVUK0wI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "8e2a53c6-0d8f-4bf9-d360-e4fb1e498769"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-756989537.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmaskPaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMASK_DATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainMasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestMasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaskPaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainImages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestImages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainMasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestMasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "# load the image and mask filepaths in a sorted manner\n",
        "\n",
        "imagePaths = sorted(list(paths.list_images(IMAGE_DATASET_PATH)))\n",
        "maskPaths = sorted(list(paths.list_images(MASK_DATASET_PATH)))\n",
        "\n",
        "trainImages, testImages, trainMasks, testMasks = train_test_split(imagePaths, maskPaths,test_size=TEST_SPLIT, random_state=seed)\n",
        "len(trainImages), len(testImages), len(trainMasks), len(testMasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxX3kdfRK0zL"
      },
      "outputs": [],
      "source": [
        "#create dataset class\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "class SegmentationDataset(Dataset):\n",
        "\tdef __init__(self, imagePaths, maskPaths, transforms):\n",
        "\t\t# store the image and mask filepaths, and augmentation\n",
        "\t\t# transforms\n",
        "\t\tself.imagePaths = imagePaths\n",
        "\t\tself.maskPaths = maskPaths\n",
        "\t\tself.transforms = transforms\n",
        "\tdef __len__(self):\n",
        "\t\t# return the number of total samples contained in the dataset\n",
        "\t\treturn len(self.imagePaths)\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\t# grab the image path from the current index\n",
        "\t\timagePath = self.imagePaths[idx]\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\t\tmask = cv2.imread(self.maskPaths[idx], 0)\n",
        "\n",
        "\t\tif self.transforms is not None:\n",
        "\t\t\t# apply the transformations to both image and its mask\n",
        "\t\t\timage = self.transforms(image)\n",
        "\t\t\tmask = self.transforms(mask)\n",
        "\t\t# return a tuple of the image and its mask\n",
        "\t\treturn (image, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXbGbXoBK01r"
      },
      "outputs": [],
      "source": [
        "# define transformations\n",
        "from PIL import Image\n",
        "transforms1 = transforms.Compose([transforms.ToPILImage(),\n",
        " \ttransforms.Resize((INPUT_IMAGE_HEIGHT, INPUT_IMAGE_WIDTH),interpolation= Image.NEAREST),\n",
        "\ttransforms.ToTensor()])\n",
        "\n",
        "# create the train and test datasets\n",
        "trainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks,transforms=transforms1)\n",
        "testDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks,transforms=transforms1)\n",
        "\n",
        "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
        "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
        "\n",
        "# create the training and test data loaders\n",
        "trainLoader = DataLoader(trainDS, shuffle=True, batch_size= BATCH_SIZE, num_workers=os.cpu_count()) #pin_memory= PIN_MEMORY\n",
        "testLoader = DataLoader(testDS, shuffle=False, batch_size= BATCH_SIZE, num_workers=os.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGmDHNkoK04p"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# obtain a batch of training data\n",
        "inputs, masks = next(iter(trainLoader))\n",
        "\n",
        "print(\"Shape of the inputs tensor:\", inputs.shape)\n",
        "print(\"Shape of the masks tensor:\", masks.shape)\n",
        "\n",
        "# plot the images and masks from the batch\n",
        "fig, axs = plt.subplots(4, 2, figsize=(12, 6))\n",
        "for i in range(4):\n",
        "    for j in range(2):\n",
        "        idx = i*2+j\n",
        "        # extract the image and mask tensors from the batch\n",
        "        img_tensor = inputs[idx]\n",
        "        mask_tensor = masks[idx]\n",
        "        # convert the tensors to numpy arrays and transpose the dimensions\n",
        "        img = img_tensor.permute(1, 2, 0).numpy()\n",
        "        mask = mask_tensor.squeeze().numpy()\n",
        "        # plot the image and mask side-by-side\n",
        "        axs[i, j].imshow(img)\n",
        "        axs[i, j].imshow(mask,alpha = 0.5)\n",
        "        axs[i, j].axis('off')\n",
        "plt.show()\n",
        "\n",
        "unique_values = masks.unique()\n",
        "print(\"Unique values in the mask tensor:\", unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH7jrbKHqxZ6"
      },
      "outputs": [],
      "source": [
        "class AFF(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, channels, r=4):\n",
        "        super(AFF, self).__init__()\n",
        "        inter_channels = int(channels // r)\n",
        "\n",
        "        self.local_att = nn.Sequential(\n",
        "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(inter_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(channels),\n",
        "        )\n",
        "\n",
        "        self.global_att = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, inter_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(inter_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(inter_channels, channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(channels),\n",
        "        )\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x, outI, feature_Level):\n",
        "        xa = x + outI + feature_Level # x = I_out4, outI = x5,  feature_Level = x4\n",
        "        #print(\"Inside AFF xa: \", xa.size())\n",
        "        xl = self.local_att(xa)\n",
        "        #print(\"Inside AFF xl: \", xl.size())\n",
        "        xg = self.global_att(xa)\n",
        "        #print(\"Inside AFF xg: \", xg.size())\n",
        "        xlg = xl + xg\n",
        "        #print(\"Inside AFF xlg: \", xlg.size())\n",
        "        wei = self.sigmoid(xlg)\n",
        "\n",
        "        xo = 2 * x * wei + 2 * outI * (1 - wei)\n",
        "        #print(\"Inside AFF xo: \", wei.size())\n",
        "        return xo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckfrm2OIAi2U"
      },
      "outputs": [],
      "source": [
        "class Model1(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(Model1, self).__init__()\n",
        "\n",
        "        #for single conv\n",
        "        self.conv1_single = nn.Conv2d(1, 1, kernel_size=1, padding=0)\n",
        "        self.conv_single = nn.Conv2d(channels, channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.spatial_maxpool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.spatial_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "\n",
        "    def forward(self, F1, F2, F3):\n",
        "\n",
        "        FRi = F1 + F2 + F3 # F1 = I_out4, F2 = x5, F3 = x4\n",
        "\n",
        "        channel_maxpool = torch.max(FRi, dim=1, keepdim=True)[0] # maxpool return two variable(value, index)\n",
        "        channel_avgpool = torch.mean(FRi, dim=1, keepdim=True)\n",
        "\n",
        "        xl = self.relu(self.conv_single(FRi)) * FRi\n",
        "        #print(\"local features: \", xl.shape)\n",
        "\n",
        "        # # Global Average Pooling (spatial-wise pooling, channel will be same)\n",
        "        GAP = self.relu(self.conv_single(self.spatial_avgpool(FRi)))* FRi\n",
        "        #print(\"GAP: \", GAP.shape)\n",
        "\n",
        "\n",
        "        # for single conv\n",
        "        #GMP = self.sigmoid(self.conv_single(self.spatial_maxpool(FRi)))* FRi\n",
        "        GMP = self.relu(self.conv_single(self.spatial_maxpool(FRi)))* FRi\n",
        "        #print(\"GMP: \", GMP.shape)\n",
        "\n",
        "\n",
        "        # for single conv\n",
        "        #MP = self.sigmoid(self.conv1_single(channel_maxpool)) * FRi\n",
        "        MP = self.relu(self.conv1_single(channel_maxpool)) * FRi\n",
        "        #print(\"MP: \", MP.shape)\n",
        "\n",
        "\n",
        "\n",
        "        # for single conv\n",
        "        #AP = self.sigmoid(self.conv1_single(channel_avgpool)) * FRi\n",
        "        AP = self.relu(self.conv1_single(channel_avgpool)) * FRi\n",
        "        #print(\"AP:\", AP.shape)\n",
        "\n",
        "\n",
        "        addition = GAP + xl + AP\n",
        "\n",
        "        addition = self.sigmoid(addition)\n",
        "        #print(\"Output: \", addition. shape)\n",
        "\n",
        "        #xo = 2 * F1 * addition + 2 * F3 * (1 - addition)\n",
        "        xo = 2 * F1 * addition + 2 * F2 * (1 - addition)\n",
        "        #print(\"xo: \", xo. shape)\n",
        "\n",
        "        return addition\n",
        "#Sample usage\n",
        "# fem = Model1(channels=64)\n",
        "# input_tensor1 = torch.randn(4, 64, 240, 240)\n",
        "# input_tensor2 = torch.randn(4, 64, 240, 240)\n",
        "# output_tensor = fem(input_tensor1,input_tensor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf32Z6C70wG-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, AFF_channel, bilinear=False):\n",
        "    #def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        #self.model1 = Model1(AFF_channel)\n",
        "        self.aff= AFF(AFF_channel)\n",
        "        #self.iaff = iAFF(AFF_channel)\n",
        "\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels) #AFF\n",
        "\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels//2, out_channels)\n",
        "\n",
        "\n",
        "    #def forward(self, x1, x2):\n",
        "    def forward(self, x1, x2, x3):\n",
        "        #print(\"inside forward up( initial call) x1 and x2: \", x1.size(),x2.size())\n",
        "        x1 = self.up(x1) # during first call x1 = x5, x2 = x4 (x1, x2, x3 == x5, I_out_4, x4)\n",
        "        #print(\"inside after calling up, x1=x5: \", x1.size())\n",
        "        #input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        #x = self.model1(x2,x1,x3)\n",
        "        x = self.aff(x2,x1,x3)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "       return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jO-F8ZPoU2Z"
      },
      "outputs": [],
      "source": [
        "#class CLSCA(nn.Module):\n",
        "class UAFF(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False, dropout_rate=0.0):\n",
        "        #super(CLSCA, self).__init__()\n",
        "        super(UAFF, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.spatial_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        #channel_maxpool = torch.max(FRi, dim=1, keepdim=True)[0]\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "           )\n",
        "\n",
        "        self.trans_conv1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "           )\n",
        "\n",
        "        self.trans_conv2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "           )\n",
        "\n",
        "        self.trans_conv3 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "           )\n",
        "\n",
        "        self.trans_conv4 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "\n",
        "\n",
        "        \"\"\" For AFF and iAFF\"\"\"\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        #factor = 2 if bilinear else 1\n",
        "        factor = 2\n",
        "        self.down4 = Down(512, 1024)\n",
        "        self.up1 = Up(1024, 512 , 512)\n",
        "        self.up2 = Up(512, 256, 256)\n",
        "        self.up3 = Up(256, 128 , 128)\n",
        "        self.up4 = Up(128, 64, 64)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        s1 = self.spatial_avgpool(x1)\n",
        "        c1 = torch.mean(x1, dim=1, keepdim=True)\n",
        "        mul1 = s1 * c1\n",
        "\n",
        "        x2 = self.down1(x1)\n",
        "        s2 = self.spatial_avgpool(x2)\n",
        "        c2 = torch.mean(x2, dim=1, keepdim=True)\n",
        "        mul2 = s2 * c2\n",
        "\n",
        "        Trans_conv1 = self.trans_conv1(mul2)\n",
        "        I_out_1 = self.conv1(mul1 + Trans_conv1)\n",
        "        I_out_1 = I_out_1 * x1\n",
        "\n",
        "        x3 = self.down2(x2)\n",
        "        s3 = self.spatial_avgpool(x3)\n",
        "        c3 = torch.mean(x3, dim=1, keepdim=True)\n",
        "        mul3 = s3 * c3\n",
        "\n",
        "        Trans_conv2 = self.trans_conv2(mul3)\n",
        "        I_out_2 = self.conv2(mul2 + Trans_conv2)\n",
        "        I_out_2 =  I_out_2 * x2\n",
        "        x4 = self.down3(x3)\n",
        "        s4 = self.spatial_avgpool(x4)\n",
        "        c4 = torch.mean(x4, dim=1, keepdim=True)\n",
        "        mul4 = s4 * c4\n",
        "        Trans_conv3 = self.trans_conv3(mul4)\n",
        "        I_out_3 = self.conv3(mul3 + Trans_conv3)\n",
        "        I_out_3 =  I_out_3 * x3\n",
        "\n",
        "        x5 = self.down4(x4)\n",
        "        s5 = self.spatial_avgpool(x5)\n",
        "        c5 = torch.mean(x5, dim=1, keepdim=True)\n",
        "        mul5 = s5 * c5\n",
        "\n",
        "        Trans_conv4 = self.trans_conv4(mul5)\n",
        "        I_out_4 = self.conv4(mul4 + Trans_conv4)\n",
        "        I_out_4 = I_out_4 * x4\n",
        "\n",
        "\n",
        "        x = self.up1(x5, I_out_4, x4)\n",
        "        x = self.up2(x, I_out_3, x3)\n",
        "        x = self.up3(x, I_out_2, x2)\n",
        "        x = self.up4(x, I_out_1, x1)\n",
        "        logits = self.outc(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Pxza_kXK1Hz"
      },
      "outputs": [],
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm\n",
        "criterion = BCEWithLogitsLoss()\n",
        "NUM_EPOCHS = 70\n",
        "trainSteps = len(trainDS) // BATCH_SIZE\n",
        "testSteps = len(testDS) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKpKxuRCDpQQ"
      },
      "outputs": [],
      "source": [
        "def evaluation_metrices(output, target):\n",
        "  smooth = 1e-5\n",
        "\n",
        "  if torch.is_tensor(output):\n",
        "    output = torch.sigmoid(output).data.cpu().numpy()\n",
        "  if torch.is_tensor(target):\n",
        "    target = target.data.cpu().numpy()\n",
        "\n",
        "    output_ = output > 0.5\n",
        "    target_ = target > 0.5\n",
        "\n",
        "    true_positives = (output_ & target_).sum()\n",
        "    false_positives = (output_ & ~target_).sum()\n",
        "    false_negatives = (~output_ & target_).sum()\n",
        "    true_negatives = (~output_ & ~target_).sum()\n",
        "\n",
        "    sensitivity = (true_positives ) #/ (true_positives + false_negatives )\n",
        "    specificity = (true_negatives) #/ (true_negatives + false_positives )\n",
        "    accuracy = (true_positives + true_negatives ) #/ (true_positives + true_negatives + false_positives + false_negatives )\n",
        "\n",
        "\n",
        "    intersection = true_positives\n",
        "    union = true_positives + false_positives + false_negatives\n",
        "\n",
        "    iou = intersection  #/ (union + smooth)\n",
        "    dice = 2 * intersection  #/ (union + intersection + smooth)\n",
        "\n",
        "    #iou = (intersection + smooth) / (union + smooth)\n",
        "    #dice = (2 * intersection + smooth) / (union + intersection + smooth)\n",
        "\n",
        "    return iou, dice, accuracy, sensitivity, specificity, true_positives, false_positives, false_negatives, true_negatives\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mb06GPe1Klr"
      },
      "outputs": [],
      "source": [
        "# my training loop\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "H = {\"train_loss\": [], \"train_iou\": [], \"val_loss\": [],\"val_iou\": [], \"dice_score\": [], \"accuracy\": [], \"sensitivity\": [], \"specificity\": []}\n",
        "\n",
        "def main():\n",
        "\n",
        "\n",
        "    model = UAFF(3,1,bilinear=False)\n",
        "\n",
        "    #move to GPU\n",
        "    print('\\nmoving models to GPU ...')\n",
        "    ##model = torch.nn.DataParallel(model).cuda()\n",
        "    model.cuda()\n",
        "    criterion.to(DEVICE)\n",
        "    print('done\\n')\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=2.0e-4, weight_decay=0) # for BUSI 2.0e-4 without scheduler other 1.0e-4 with schedular\n",
        "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "    print(\"[INFO] training the network...\")\n",
        "\n",
        "    startTime = time.time()\n",
        "\n",
        "    best_iou = 0\n",
        "    trigger = 0\n",
        "    patience = 20\n",
        "\n",
        "    for e in tqdm(range(NUM_EPOCHS)):\n",
        "\t  # set the model in training mode\n",
        "          #epoch_start_time = time.time()\n",
        "\n",
        "          train_loss, train_iou, train_iou_Deno = train_function(trainLoader, model, criterion, optimizer)\n",
        "          totalValLoss, val_iou, val_dice, val_accuracy,val_sensitivity,val_specificity, val_sen_Deno, val_spc_Deno,val_iou_Deno, val_dice_Deno = val_function(testLoader, model, criterion, optimizer)\n",
        "          # scheduler.step()\n",
        "\n",
        "\n",
        "\t# calculate the average training and validation loss\n",
        "          avgTrainLoss = train_loss / trainSteps\n",
        "          avgTrainIoU = train_iou/ train_iou_Deno\n",
        "          avgValLoss = totalValLoss / testSteps\n",
        "          avgValIoU = val_iou / val_iou_Deno\n",
        "          avgValDice = val_dice/ val_dice_Deno\n",
        "          avgValAcc = val_accuracy/ (len(testDS)*(240*240))\n",
        "          avgValSen = val_sensitivity/ val_sen_Deno\n",
        "          avgValSpe = val_specificity/ val_spc_Deno\n",
        "\n",
        "          print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
        "          print(\"Train loss: {:.4f}, Val loss: {:.4f}, Train_iou: {:.4f}, Val_iou: {:.4f}\".format(avgTrainLoss, avgValLoss, avgTrainIoU,avgValIoU))\n",
        "          print(\"Dice Score: {:.4f}, Accuracy: {:.4f}, Sensitivity: {:.4f}, Specificity: {:.4f}\".format(avgValDice,avgValAcc,avgValSen,avgValSpe))\n",
        "\n",
        "          if avgValIoU > best_iou:\n",
        "\n",
        "             torch.save(model.state_dict(),'/content/gdrive/MyDrive/Phd work/Saved_model /u-net/UAFF-New-Save/ISIC.pth')\n",
        "             best_iou=avgValIoU\n",
        "             print(\"saved best model based on IOU: \", best_iou )\n",
        "             trigger = 0\n",
        "          else:\n",
        "             trigger += 1\n",
        "             print(f'EarlyStopping counter: {trigger} out of {patience}')\n",
        "\n",
        "          if trigger >= patience:\n",
        "                  print(\"Early stopping triggered\")\n",
        "                  break\n",
        "\n",
        "\t# update our training history\n",
        "          if (e%1==0):\n",
        "              H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "              H[\"train_iou\"].append(avgTrainIoU) # The cpu() method is used to move the tensor from GPU to CPU (if it is on the GPU)\n",
        "                                                                      # because numpy arrays can only be created from tensors on CPU.\n",
        "              H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
        "              H[\"val_iou\"].append(avgValIoU)\n",
        "              H[\"dice_score\"].append(avgValDice)\n",
        "              H[\"accuracy\"].append(avgValAcc)\n",
        "              H[\"sensitivity\"].append(avgValSen)\n",
        "              H[\"specificity\"].append(avgValSpe)\n",
        "\n",
        "\n",
        "    endTime = time.time()\n",
        "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n",
        "\n",
        "    df = pd.DataFrame(H)\n",
        "    df.to_csv('/content/gdrive/MyDrive/Phd work/Saved_model /u-net/UAFF-New-Save/ISIC.csv', index=False)\n",
        "\n",
        "    epochs_range = range(1, len(H['train_iou'])+1)\n",
        "\n",
        "    plt.plot(epochs_range, H['train_iou'], label='train_iou')\n",
        "    plt.plot(epochs_range, H['val_iou'], label='val_iou')\n",
        "    plt.title('IOU vs Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('IOU')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.tight_layout()\n",
        "    time.sleep(4)\n",
        "\n",
        "    plt.savefig('/content/gdrive/MyDrive/Phd work/Paper_Results/UNet.png')\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def train_function(trainLoader, model, criterion, optimizer):\n",
        "          model.train()\n",
        "          totalTrainLoss = 0\n",
        "          train_iou = 0\n",
        "          train_iou_Deno = 0\n",
        "\n",
        "\t # loop over the training set\n",
        "          for (i, (x, y)) in enumerate(trainLoader):\n",
        "\t\t# send the input to the device\n",
        "              (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
        "              #torch.cuda.empty_cache()\n",
        "              #gc.collect()\n",
        "              output = model(x) #output is the raw output from the model\n",
        "              loss = criterion(output, y)\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              totalTrainLoss += loss\n",
        "              #pred = output.argmax(dim=1)\n",
        "              iou, dice, accuracy, sensitivity, specificity, true_positives, false_positives, \\\n",
        "              false_negatives, true_negatives = evaluation_metrices(output,y)\n",
        "              train_iou += iou\n",
        "              train_iou_Deno += true_positives + false_positives + false_negatives\n",
        "          return totalTrainLoss, train_iou, train_iou_Deno\n",
        "\n",
        "def val_function(testLoader, model, criterion, optimizer):\n",
        "       totalValLoss = 0\n",
        "       val_iou = 0\n",
        "       val_dice = 0\n",
        "       val_accuracy = 0\n",
        "       val_sensitivity = 0\n",
        "       val_specificity = 0\n",
        "       val_sen_Deno = 0\n",
        "       val_spc_Deno = 0\n",
        "       val_iou_Deno = 0\n",
        "       val_dice_Deno = 0\n",
        "\n",
        "       with torch.no_grad():\n",
        "\n",
        "              model.eval() # set the model in evaluation mode\n",
        "\n",
        "              for (x,y) in testLoader:\n",
        "                  (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
        "                  output = model(x)\n",
        "                  ValLoss = criterion(output, y)\n",
        "                  totalValLoss += ValLoss\n",
        "                  iou, dice, accuracy, sensitivity, specificity, true_positives,\\\n",
        "                  false_positives, false_negatives, true_negatives = evaluation_metrices(output,y)\n",
        "                  val_iou += iou\n",
        "                  val_dice += dice\n",
        "                  val_accuracy +=accuracy\n",
        "                  val_sensitivity += sensitivity\n",
        "                  val_specificity += specificity\n",
        "                  val_sen_Deno += true_positives + false_negatives\n",
        "                  val_spc_Deno += true_negatives + false_positives\n",
        "                  val_iou_Deno += true_positives + false_positives + false_negatives\n",
        "                  val_dice_Deno += 2*true_positives + false_positives + false_negatives\n",
        "              return totalValLoss, val_iou, val_dice, val_accuracy, val_sensitivity, val_specificity, val_sen_Deno, val_spc_Deno, val_iou_Deno, val_dice_Deno\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAjP_0Zn0sAr"
      },
      "outputs": [],
      "source": [
        "# Use this if you need to run multiple time\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2o-oByZvoiUl"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import optuna\n",
        "# from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# db_url = \"sqlite:////content/gdrive/MyDrive/Phd work/SAVE_SQL/test.db\"\n",
        "\n",
        "# def objective(trial):\n",
        "#     # Define hyperparameters to be optimized\n",
        "#     lr = trial.suggest_float(\"lr\", 2e-5, 1e-3, log=True)\n",
        "\n",
        "#     weight_decay = trial.suggest_float(\"weight_decay\", 2e-5, 1e-3, log=True)\n",
        "#     dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
        "\n",
        "#     # Learning rate scheduler parameters\n",
        "#     step_size = trial.suggest_int('step_size', 1, 10)\n",
        "#     gamma = trial.suggest_float('gamma', 0.1, 1.0)\n",
        "\n",
        "\n",
        "#     IoU = main(lr,weight_decay,dropout_rate, step_size, gamma)\n",
        "\n",
        "#     return IoU\n",
        "\n",
        "\n",
        "\n",
        "# H = {\"train_loss\": [], \"train_iou\": [], \"val_loss\": [],\"val_iou\": [], \"dice_score\": [], \"accuracy\": [], \"sensitivity\": [], \"specificity\": []}\n",
        "\n",
        "\n",
        "# def main(lr=1e-4, weight_decay=0, dropout_rate = .1, step_size=5, gamma=.1):\n",
        "\n",
        "#     model = UNetAFF(3,1,bilinear=False,dropout_rate=dropout_rate)\n",
        "\n",
        "#     print('\\nmoving models to GPU ...')\n",
        "#     model.cuda()\n",
        "#     criterion.to(DEVICE)\n",
        "#     print('done\\n')\n",
        "\n",
        "#    # Select optimizer based on trial suggestion\n",
        "\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "#     startTime = time.time()\n",
        "\n",
        "#     best_iou = 0\n",
        "#     trigger = 0\n",
        "#     patience = 20\n",
        "\n",
        "#     for e in tqdm(range(NUM_EPOCHS)):\n",
        "# \t  # set the model in training mode\n",
        "#           train_loss, train_iou, train_iou_Deno = train_function(trainLoader, model, criterion, optimizer)\n",
        "#           totalValLoss, val_iou, val_dice, val_accuracy,val_sensitivity,val_specificity, val_sen_Deno, val_spc_Deno,val_iou_Deno, val_dice_Deno = val_function(testLoader, model, criterion, optimizer)\n",
        "#           scheduler.step()\n",
        "\n",
        "# \t# calculate the average training and validation loss\n",
        "#           avgTrainLoss = train_loss / trainSteps\n",
        "#           avgTrainIoU = train_iou/ train_iou_Deno\n",
        "\n",
        "#           avgValLoss = totalValLoss / testSteps\n",
        "#           avgValIoU = val_iou / val_iou_Deno\n",
        "#           avgValDice = val_dice/ val_dice_Deno\n",
        "#           avgValAcc = val_accuracy/ (len(testDS)*(240*240))\n",
        "#           avgValSen = val_sensitivity/ val_sen_Deno\n",
        "#           avgValSpe = val_specificity/ val_spc_Deno\n",
        "\n",
        "#           print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
        "#           print(\"Train loss: {:.4f}, Val loss: {:.4f}, Train_iou: {:.4f}, Val_iou: {:.4f}\".format(avgTrainLoss, avgValLoss, avgTrainIoU,avgValIoU))\n",
        "#           print(\"Dice Score: {:.4f}, Accuracy: {:.4f}, Sensitivity: {:.4f}, Specificity: {:.4f}\".format(avgValDice,avgValAcc,avgValSen,avgValSpe))\n",
        "\n",
        "#           if avgValIoU > best_iou:\n",
        "\n",
        "#              torch.save(model.state_dict(),'/content/gdrive/MyDrive/Phd work/UNet++/UNetAFF.pth')\n",
        "\n",
        "#              best_iou=avgValIoU\n",
        "#              print(\"saved best model based on IOU: \", best_iou )\n",
        "#              trigger = 0\n",
        "#           else:\n",
        "#              trigger += 1\n",
        "#              print(f'EarlyStopping counter: {trigger} out of {patience}')\n",
        "\n",
        "#           if trigger >= patience:\n",
        "#                   #torch.save(model.state_dict(),'/content/gdrive/MyDrive/Phd work/UNet++/UNetAFF.pth')\n",
        "#                   print(\"Early stopping triggered\")\n",
        "#                   break\n",
        "\n",
        "# \t# update our training history\n",
        "#           if (e%1==0):\n",
        "#               H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "#               H[\"train_iou\"].append(avgTrainIoU) # The cpu() method is used to move the tensor from GPU to CPU (if it is on the GPU)\n",
        "#                                                                       # because numpy arrays can only be created from tensors on CPU.\n",
        "#               H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
        "#               H[\"val_iou\"].append(avgValIoU)\n",
        "#               H[\"dice_score\"].append(avgValDice)\n",
        "#               H[\"accuracy\"].append(avgValAcc)\n",
        "#               H[\"sensitivity\"].append(avgValSen)\n",
        "#               H[\"specificity\"].append(avgValSpe)\n",
        "\n",
        "\n",
        "#     endTime = time.time()\n",
        "#     print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n",
        "\n",
        "#     df = pd.DataFrame(H)\n",
        "\n",
        "#     df.to_csv('/content/gdrive/MyDrive/Phd work/Paper_Results/UNet_Updated.csv', index=False)\n",
        "\n",
        "#     epochs_range = range(1, len(H['train_iou'])+1)\n",
        "\n",
        "#     plt.plot(epochs_range, H['train_iou'], label='train_iou')\n",
        "#     plt.plot(epochs_range, H['val_iou'], label='val_iou')\n",
        "#     plt.title('IOU vs Epoch')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.ylabel('IOU')\n",
        "#     plt.legend()\n",
        "#     plt.show()\n",
        "#     plt.tight_layout()\n",
        "#     time.sleep(4)\n",
        "\n",
        "#     plt.savefig('/content/gdrive/MyDrive/Phd work/Paper_Results/UNet.png')\n",
        "\n",
        "\n",
        "#     torch.cuda.empty_cache()\n",
        "\n",
        "#     return avgValIoU\n",
        "\n",
        "\n",
        "# def train_function(trainLoader, model, criterion, optimizer):\n",
        "#           model.train()\n",
        "#           totalTrainLoss = 0\n",
        "#           train_iou = 0\n",
        "#           train_iou_Deno = 0\n",
        "\n",
        "# \t # loop over the training set\n",
        "#           for (i, (x, y)) in enumerate(trainLoader):\n",
        "# \t\t# send the input to the device\n",
        "#               (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
        "#               #torch.cuda.empty_cache()\n",
        "#               #gc.collect()\n",
        "#               output = model(x) #output is the raw output from the model\n",
        "#               loss = criterion(output, y)\n",
        "#               optimizer.zero_grad()\n",
        "#               loss.backward()\n",
        "#               optimizer.step()\n",
        "#               totalTrainLoss += loss\n",
        "#               #pred = output.argmax(dim=1)\n",
        "#               iou, dice, accuracy, sensitivity, specificity, true_positives, false_positives, \\\n",
        "#               false_negatives, true_negatives = evaluation_metrices(output,y)\n",
        "#               train_iou += iou\n",
        "#               train_iou_Deno += true_positives + false_positives + false_negatives\n",
        "#           return totalTrainLoss, train_iou, train_iou_Deno\n",
        "\n",
        "# def val_function(testLoader, model, criterion, optimizer):\n",
        "#        totalValLoss = 0\n",
        "#        val_iou = 0\n",
        "#        val_dice = 0\n",
        "#        val_accuracy = 0\n",
        "#        val_sensitivity = 0\n",
        "#        val_specificity = 0\n",
        "#        val_sen_Deno = 0\n",
        "#        val_spc_Deno = 0\n",
        "#        val_iou_Deno = 0\n",
        "#        val_dice_Deno = 0\n",
        "\n",
        "#        with torch.no_grad():\n",
        "\n",
        "#               model.eval() # set the model in evaluation mode\n",
        "\n",
        "#               for (x,y) in testLoader:\n",
        "#                   (x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
        "#                   output = model(x)\n",
        "#                   ValLoss = criterion(output, y)\n",
        "#                   totalValLoss += ValLoss\n",
        "#                   iou, dice, accuracy, sensitivity, specificity, true_positives,\\\n",
        "#                   false_positives, false_negatives, true_negatives = evaluation_metrices(output,y)\n",
        "#                   val_iou += iou\n",
        "#                   val_dice += dice\n",
        "#                   val_accuracy +=accuracy\n",
        "#                   val_sensitivity += sensitivity\n",
        "#                   val_specificity += specificity\n",
        "#                   val_sen_Deno += true_positives + false_negatives\n",
        "#                   val_spc_Deno += true_negatives + false_positives\n",
        "#                   val_iou_Deno += true_positives + false_positives + false_negatives\n",
        "#                   val_dice_Deno += 2*true_positives + false_positives + false_negatives\n",
        "#               return totalValLoss, val_iou, val_dice, val_accuracy,val_sensitivity, val_specificity, val_sen_Deno, val_spc_Deno, val_iou_Deno, val_dice_Deno\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     #study = optuna.create_study(direction=\"maximize\")\n",
        "#     study = optuna.create_study(direction=\"maximize\", study_name=\"unet-aff-optimization\", storage=db_url, load_if_exists=True)\n",
        "\n",
        "#     study.optimize(objective, n_trials=60)\n",
        "\n",
        "#     print(\"Number of finished trials:\", len(study.trials))\n",
        "#     print(\"Best trial:\", study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qdWCMFG8tz34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqaXayQRUUYJ"
      },
      "outputs": [],
      "source": [
        "# for evaluation purpose\n",
        "\n",
        "# IMAGE_DATASET_PATH_E = '/content/gdrive/MyDrive/Phd work/UNet++/Eva_Image/'\n",
        "# MASK_DATASET_PATH_E = '/content/gdrive/MyDrive/Phd work/UNet++/Eva_mask/'\n",
        "IMAGE_DATASET_PATH_E = '/content/gdrive/MyDrive/Phd work/ISIC 2017/New_Eva_17/'\n",
        "MASK_DATASET_PATH_E = '/content/gdrive/MyDrive/Phd work/ISIC 2017/New_Mask_Eva_17/'\n",
        "\n",
        "imagePaths_E = sorted(list(paths.list_images(IMAGE_DATASET_PATH_E)))\n",
        "maskPaths_E = sorted(list(paths.list_images(MASK_DATASET_PATH_E)))\n",
        "\n",
        "trainDS_E = SegmentationDataset(imagePaths=imagePaths_E, maskPaths=maskPaths_E,transforms=transforms1)\n",
        "\n",
        "print(f\"[INFO] found {len(trainDS_E)} examples in the training set...\")\n",
        "\n",
        "trainLoader_E = DataLoader(trainDS_E, shuffle=False, batch_size= 5, num_workers=os.cpu_count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQTP94h_UUjW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "\n",
        "#dir_name = '/content/gdrive/MyDrive/Phd work/Paper_Results/Evaluation_image/Final_U_Net_ISIC/'\n",
        "\n",
        "\n",
        "model =  UAFF(3,1,bilinear=False)\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/Phd work/Saved_model /u-net/UAFF-New-Save/ISIC.pth'))\n",
        "\n",
        "# Load a sample image and mask pair from trainLoader\n",
        "for image, mask in trainLoader_E:\n",
        "    break\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "\n",
        "# Load random sample image and mask pair from trainLoader\n",
        "# random_samples = random.sample(list(trainLoader_E), 5)\n",
        "# for i, (image, mask) in enumerate(random_samples):\n",
        "#     break\n",
        "# with torch.no_grad():\n",
        "#     output = model(image)\n",
        "\n",
        "\n",
        "print(\"output B: \", output.shape)\n",
        "output = output.squeeze(1).cpu().numpy()\n",
        "print(\"output A: \", output.shape)\n",
        "#if torch.is_tensor(output):\n",
        "#output = torch.sigmoid(output).data.cpu().numpy()  have to check with this\n",
        "output = output > 0.5\n",
        "\n",
        "# Plot the image, mask, and segmented result\n",
        "fig, ax = plt.subplots(5, 3, figsize=(5, 10)) #, gridspec_kw={'width_ratios': [1, 1, 1]})\n",
        "for i in range(5):\n",
        "    if i==0:\n",
        "      ax[i][0].set_title('Image')\n",
        "      ax[i][1].set_title('GT')\n",
        "      ax[i][2].set_title('Output')\n",
        "\n",
        "    ax[i][0].imshow(image[i].squeeze().permute(1, 2, 0))\n",
        "    ax[i][1].imshow(mask[i].squeeze(), cmap='gray')\n",
        "    ax[i][2].imshow(output[i], cmap='gray')\n",
        "\n",
        "    fig.subplots_adjust(wspace=0.05,hspace=0.01)\n",
        "\n",
        "    # saving files for all images\n",
        "    # flattened_image = image[i].permute(1, 2, 0).reshape(-1, 3).numpy()\n",
        "    # img_df = pd.DataFrame(flattened_image)\n",
        "    # mask_df = pd.DataFrame(mask[i].numpy().squeeze(0))\n",
        "    # out_df = pd.DataFrame(output[i])\n",
        "\n",
        "    # img_df.to_csv(os.path.join(dir_name,f'img{i}.csv'),index=False)\n",
        "    # mask_df.to_csv(os.path.join(dir_name, f'mask{i}.csv'),index=False)\n",
        "    # out_df.to_csv(os.path.join(dir_name,f'output{i}.csv'),index=False)\n",
        "\n",
        "    for a in ax[i]:\n",
        "        a.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwlWlfD3OZRJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}